{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MawYEAISK80L"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "As part of this course, students will participate in an in-class real-time financial forecasting competition similar to the [M6](https://m6competition.com/). The competition will require students to augment open-source financial data with external open-source datasets of their choice. They will then present their findings to the class by the end of the course.\n",
        "\n",
        "The focus of the forecasting competition will be on several key areas, including the ability to estimate future returns and uncertainty, combining estimates into an investment decision, developing a consistent investment strategy, utilizing alternative datasets effectively, and learning from mistakes through teamwork and transparency.\n",
        "\n",
        "The winning students of the competition will be guaranteed an A+ and will receive a special prize as recognition for their achievement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd12u5I9DxG4"
      },
      "source": [
        "# Schedule\n",
        "\n",
        "The competition will take place in real-time during the semester.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYD8yv-FD2dP"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "The competition will consist of two distinct challenges: Forecasting, which will be evaluated using the ranked probability score, and Investment decisions, which will be evaluated using the information ratio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkNEtuFcD2qm"
      },
      "source": [
        "# Data\n",
        "\n",
        "The competition's investment universe will consist of three asset classes: 50 stocks from the S&P 500 index, 50 international ETFs, and 10 cryptocurrencies. These assets have been selected to provide a broad representation of the overall market."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zp5T28MD2s7"
      },
      "source": [
        "# Submission format\n",
        "\n",
        "The competition will have 10 submission points, plus an additional test point, with a deadline of 6 PM ET on the Sunday before the start of the corresponding investment period. Participants are required to submit their forecasts and investment decisions at each point, outlining their predictions and strategy for the upcoming week. The forecast horizon is one week, typically five trading days, and there will be no overlapping evaluation periods.\n",
        "\n",
        "**Example**: The deadline for the first submission point is 6 PM ET on September 17th, 2022 (Sunday). Participants are required to submit forecasts and investment decisions reflecting the closing value of the last trading day of the following week, which is September 22nd, 2022 (Friday).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT-xrfyQyzKy"
      },
      "source": [
        "At each submission point, students may submit a single **csv file** (make sure you are submitting a csv file. must be *.csv) consisting of seven columns of 110 values each (one per asset):\n",
        "\n",
        "* The first column must indicate the asset to which the forecasts and the respective row's investment decisions refer. The acronym of each asset will serve as an identifier.\n",
        "\n",
        "* The second to sixth columns must contain positive values summing horizontally to **unity** that refer to the probabilities of the ranks of the forecasted percentage return for each asset (stocks or ETFs); rank 1 is the lowest forecasted percentage return, and rank 5 is the highest forecasted percentage return.\n",
        "\n",
        "* The seventh column must contain numerical values corresponding to the weights for investing in each asset. These values must be positive for long positions, negative for short positions, or zero for no position.\n",
        "\n",
        "**For example**, if three assets are assigned weights 0.5, 0.3, and -0.2, respectively, and all other assets weights of 0, this means that the participant wishes to invest in only three assets with positions long, long, and short and with a budget allocation of 50%, 30%, and 20% respectively.\n",
        "\n",
        "The submission will be considered invalid if the **sum of the absolute weights** exceeds 1.\n",
        "\n",
        "If the **sum of the absolute weights** is less than 1 (less than 100%), then the remainder is assumed to be assigned to an asset with zero return and zero risk (i.e., no investment). However, if the sum of the absolute weights is below 0.25 (25%) the submission will be considered invalid (i.e., some investment must be made and some risk must be taken)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPDXwWg6Qcxm"
      },
      "source": [
        "**Example**: The following is an example for the first 8 rows of a submission file. In this case, the participant decides to invest in three assets (3rd, 6th, and 7th) with weights of 50%, 30%, and 20% (or 0.5, 0.3, and 0.2) and positions long, long, and short, respectively. Additionally, the participant forecasts that there is a probability of 0.1, 0.2, 0.5, and 0.2 that the first asset (MMM) will be ranked 2nd, 3rd, 4th, and 5th, respectively, with regards to the expected percentage return. Equally, the participantâ€™s forecast is that the second asset (ATVI) will be ranked 3rd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "GdFyuqqulik6",
        "outputId": "76e82d4f-8015-443e-dbac-950cf0beef96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 6)\n",
            "sum of abs decisions:  1.0\n",
            "sum of ranks equals 1:  True\n",
            "all ranks are non negative:  True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id rank1 rank2 rank3 rank4 rank5 decision\n",
              "0    mmm   0.0   0.1   0.2   0.5   0.2      0.0\n",
              "1   atvi   0.0   0.0   1.0   0.0   0.0      0.0\n",
              "2  googl   0.1   0.1   0.1   0.1   0.6      0.5\n",
              "3    aph   0.5   0.4  0.05  0.05   0.0      0.0\n",
              "4    bmy   0.2   0.2   0.2   0.2   0.2      0.0\n",
              "5     cb   0.0   0.0   0.1   0.4   0.5      0.3\n",
              "6    exr   0.7   0.3   0.0   0.0   0.0     -0.2\n",
              "7    msi   0.0   0.0   1.0   0.0   0.0      0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7496ce37-5470-4138-9706-2b26f1039905\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rank1</th>\n",
              "      <th>rank2</th>\n",
              "      <th>rank3</th>\n",
              "      <th>rank4</th>\n",
              "      <th>rank5</th>\n",
              "      <th>decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mmm</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atvi</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>googl</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aph</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bmy</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cb</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>exr</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>msi</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7496ce37-5470-4138-9706-2b26f1039905')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7496ce37-5470-4138-9706-2b26f1039905 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7496ce37-5470-4138-9706-2b26f1039905');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87f0465d-e311-416f-bf92-ca1e9f55ea36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87f0465d-e311-416f-bf92-ca1e9f55ea36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87f0465d-e311-416f-bf92-ca1e9f55ea36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"atvi\",\n          \"cb\",\n          \"mmm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank1\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 0.7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1,\n          0.7,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank2\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 0.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0,\n          0.3,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank3\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          0.0,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank4\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5,\n          0.0,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank5\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 0.6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          0.5,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decision\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": -0.2,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5,\n          -0.2,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "cols = ['id','rank1', 'rank2', 'rank3', 'rank4', 'rank5', 'decision']\n",
        "assets = ['mmm','atvi','googl','aph','bmy','cb','exr','msi']\n",
        "df = pd.DataFrame(columns = cols)\n",
        "df[\"id\"] = assets\n",
        "mat = np.array([[0,0.1,0.2,0.5,0.2,0],\\\n",
        "               [0,0,1,0,0,0],\\\n",
        "               [.1,.1,.1,.1,.6,.5], \\\n",
        "               [.5,.4,.05,.05,0,0], \\\n",
        "               [.2,.2,.2,.2,.2,0], \\\n",
        "               [0,0,.1,.4,.5,.3], \\\n",
        "               [.7,.3,0,0,0,-.2], \\\n",
        "               [0,0,1,0,0,0]])\n",
        "print(mat.shape)\n",
        "df.loc[:,cols[1:]] = mat\n",
        "\n",
        "print('sum of abs decisions: ', df.iloc[:,-1].abs().sum())\n",
        "print('sum of ranks equals 1: ', np.all(df.iloc[:,1:-1].sum(axis=1)==1))\n",
        "print('all ranks are non negative: ', np.all(df.iloc[:,1:-1]>=0))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9jMN1q8ONv"
      },
      "source": [
        "\\# Evaluating Forecast Performance: A Guide to Using Ranked Probability Score (RPS)\n",
        "\n",
        "To evaluate the forecast performance for a particular submission point, the **Ranked Probability Score (RPS)** is employed. Assets' realized percentage total returns over a specific period are sorted into quintiles, with rankings from 1 (lowest performance) to 5 (highest performance). In a portfolio of 110 assets, each quintile will contain 22 assets. In the event of a tie at the boundary between quintiles, all tied assets are assigned the average rank of the boundary ranks.\n",
        "\n",
        "### Example: Handling Tied Ranks\n",
        "For instance, if four assets share the 20th position, they will each receive an average rank calculated as follows:\n",
        "\n",
        "$$\n",
        "\\text{Average rank} = \\frac{(5+5+5+4)}{4} = 4.75,\n",
        "$$\n",
        "\n",
        "where the three \"5s\" represent the rank of the assets in the top quintile, and the \"4\" signifies the rank of the asset in the second quintile.\n",
        "\n",
        "### Vector Representation of Asset Ranks\n",
        "The ranking of each asset is represented by a vector $q_{i,t}$ of dimension 5. If asset $i$ ranks in quintile 3 at time $t$, then $q_{i,t} = (0, 0, 1, 0, 0)$. An asset with a rank of 4.75 at time $t$ would be represented as $q_{j,t} = (0, 0, 0, 0.25, 0.75)$.\n",
        "\n",
        "### Calculating RPS for an Individual Asset\n",
        "A forecast vector $f_{i,t}$ signifies the predicted probabilities for each rank of a particular asset, as provided by a participant. The RPS for asset $i$ at time $t$ is calculated using the following formula:\n",
        "\n",
        "$$\n",
        "RPS_{i,t} = \\frac{1}{5} \\sum_{j=1}^{5} \\left( \\sum_{k=1}^{j} q_{i,t,k} - \\sum_{k=1}^{j} f_{i,t,k} \\right)^2.\n",
        "$$\n",
        "\n",
        "### Example: Calculating RPS\n",
        "Suppose we want to determine the RPS for asset $i$ at submission point $t$. If the submitted probabilities for ranks are $f_{i,t} = (0, 0.2, 0.3, 0.4, 0.1)$ and the actual rank of the asset is 4, $q_{i,t} = (0, 0, 0, 1, 0)$, the RPS is calculated as:\n",
        "\n",
        "$$\n",
        "RPS_{i,t} = \\frac{1}{5} \\left( (0 - 0)^2 + (0 - 0.2)^2 + (0 - 0.5)^2 + (1 - 0.9)^2 + (1 - 1)^2 \\right) = 0.06.\n",
        "$$\n",
        "\n",
        "### Portfolio RPS\n",
        "The portfolio RPS at time $t$ is the average of the RPS for all $N$ assets, given by:\n",
        "\n",
        "$$\n",
        "RPS_t = \\frac{1}{N} \\sum_{i=1}^{N} RPS_{i,t},\n",
        "$$\n",
        "\n",
        "where $N$ is the total number of assets, for example, $N = 110$.\n",
        "\n",
        "### Overall RPS for Multiple Submission Points\n",
        "For multiple submission points ranging from $t_1$ to $t_2$, the overall RPS is calculated as:\n",
        "\n",
        "$$\n",
        "RPS_{t_1-t_2} = \\frac{1}{N(t_2 - t_1 + 1)} \\sum_{t=t_1}^{t_2} \\sum_{i=1}^{N} RPS_{i,t}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MKBVLsRNDX1",
        "outputId": "feec1598-aac8-4670-c83c-acba998833fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Example\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "f = np.cumsum(np.array([[0, 0.2, 0.3, 0.4, 0.1]]), axis=1)\n",
        "q = np.cumsum(np.array([[0,0,0,1,0]]), axis=1)\n",
        "np.sum((q-f)**2,axis=1)/f.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "e4RyhHT679jU",
        "outputId": "f9424828-29f7-449d-eb28-2f8c3b83ac89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0     1     2     3     4\n",
              "0  0.0  0.00  0.00  0.25  0.75\n",
              "1  0.2  0.20  0.20  0.20  0.20\n",
              "2  0.0  0.00  0.25  0.50  0.25\n",
              "3  0.0  0.25  0.50  0.25  0.00\n",
              "4  0.5  0.00  0.00  0.00  0.50\n",
              "5  0.0  0.00  0.00  0.25  0.75\n",
              "6  0.2  0.20  0.20  0.20  0.20\n",
              "7  0.0  0.00  0.25  0.50  0.25\n",
              "8  0.0  0.25  0.50  0.25  0.00\n",
              "9  0.5  0.00  0.00  0.00  0.50"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-881e6daf-7851-4e1b-97cf-5a8e7d5cb944\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-881e6daf-7851-4e1b-97cf-5a8e7d5cb944')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-881e6daf-7851-4e1b-97cf-5a8e7d5cb944 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-881e6daf-7851-4e1b-97cf-5a8e7d5cb944');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2da6d4f3-9e1a-4351-8cb7-4349d8451cbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2da6d4f3-9e1a-4351-8cb7-4349d8451cbe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2da6d4f3-9e1a-4351-8cb7-4349d8451cbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20655911179772887,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.2,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11737877907772673,\n        \"min\": 0.0,\n        \"max\": 0.25,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.2,\n          0.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19550504398153576,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2,\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1679947089113887,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2,\n          0.0,\n          0.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2736583433569839,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2,\n          0.5,\n          0.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Example\n",
        "\n",
        "#forecasting\n",
        "f = np.array([[0,0,0,0.25,0.75],[0.2,0.2,0.2,0.2,0.2],[0,0,0.25,0.5,0.25],[0,0.25,0.5,0.25,0],[0.5,0,0,0,0.5],\\\n",
        "              [0,0,0,0.25,0.75],[0.2,0.2,0.2,0.2,0.2],[0,0,0.25,0.5,0.25],[0,0.25,0.5,0.25,0],[0.5,0,0,0,0.5]])\n",
        "pd.DataFrame(data = f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "gtMaI_St8GWr",
        "outputId": "e13e5d86-4bb8-42e2-f4a6-8460eee97e64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0  1  2  3  4\n",
              "0  0  0  0  0  1\n",
              "1  0  0  0  1  0\n",
              "2  0  0  1  0  0\n",
              "3  0  1  0  0  0\n",
              "4  1  0  0  0  0\n",
              "5  0  0  0  0  1\n",
              "6  0  0  0  1  0\n",
              "7  0  0  1  0  0\n",
              "8  0  1  0  0  0\n",
              "9  1  0  0  0  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f83e9892-c00d-4a5e-a2cf-bb5a44405e10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f83e9892-c00d-4a5e-a2cf-bb5a44405e10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f83e9892-c00d-4a5e-a2cf-bb5a44405e10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f83e9892-c00d-4a5e-a2cf-bb5a44405e10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39e82bf6-ebe1-458b-96e2-07d620943884\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39e82bf6-ebe1-458b-96e2-07d620943884')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39e82bf6-ebe1-458b-96e2-07d620943884 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Example\n",
        "\n",
        "#actual\n",
        "q = np.array([[0,0,0,0,1],[0,0,0,1,0],[0,0,1,0,0],[0,1,0,0,0],[1,0,0,0,0],\\\n",
        "              [0,0,0,0,1],[0,0,0,1,0],[0,0,1,0,0],[0,1,0,0,0],[1,0,0,0,0]])\n",
        "pd.DataFrame(data = q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bexHheez_MIw",
        "outputId": "b9dc13d7-3809-4c68-b1dd-ed87060dfe77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1165"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def forecast_performance(f,q):\n",
        "\n",
        "  eps = 1e-3\n",
        "  assert np.all(q >= 0) and np.all(f >= 0) and np.all(np.abs(np.sum(f,axis=1)-1)<eps) and np.all(np.abs(np.sum(q,axis=1)-1)<eps), \\\n",
        "        \"f or q are not conditioned well\"\n",
        "\n",
        "  q = np.cumsum(q, axis=1)\n",
        "  f = np.cumsum(f, axis=1)\n",
        "  fp = np.sum((q-f)**2, axis=1)/f.shape[1] #forecast performance\n",
        "  return np.mean(fp) #mean forecast performance\n",
        "\n",
        "forecast_performance(f,q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usy__o2O9UUQ"
      },
      "source": [
        "# Evaluating Investment Performance: An Overview of the Information Ratio (IR)\n",
        "\n",
        "The Information Ratio (IR) serves as the key metric for assessing the performance of investment decisions. It is calculated as the ratio of the portfolio return ($\\text{ret}$) to the standard deviation of that return ($\\text{sdp}$):\n",
        "\n",
        "$$\n",
        "\\text{IR} = \\frac{\\text{ret}}{\\text{sdp}}\n",
        "$$\n",
        "\n",
        "Here, $\\text{ret}$ refers to the continuously compounded portfolio returns, while $\\text{sdp}$ denotes the standard deviation of these returns, computed daily. Note that the IR values presented are annualized. This version of the IR employs a benchmark return of 0, making it conceptually akin to the Sharpe Ratio with a risk-free rate of 0.\n",
        "\n",
        "## Calculating Portfolio Returns\n",
        "\n",
        "The daily portfolio holding period return, $\\text{RET}_t$, is computed using the following formula:\n",
        "\n",
        "$$\n",
        "\\text{RET}_t = \\sum_{i=1}^{N} w_i \\left( \\frac{S_{i,t}}{S_{i,t-1}} - 1 \\right)\n",
        "$$\n",
        "\n",
        "Where $N$ is the total number of assets, $w_i$ is the weight of the $i^{th}$ asset in the portfolio, and $S_{i,t}$ is the adjusted closing price of the $i^{th}$ asset at the end of trading day $t$. The term $t-1$ refers to the preceding trading day.\n",
        "\n",
        "The continuously compounded daily portfolio return, $\\text{ret}_t$, is then obtained as:\n",
        "\n",
        "$$\n",
        "\\text{ret}_t = \\log(1 + \\text{RET}_t)\n",
        "$$\n",
        "\n",
        "The value $\\text{RET}_t$ is calculated for a single day, $t$, and represents the weighted average return of the selected assets. For holding periods longer than one day, $\\text{ret}_{t_1:t_2}$ is the sum of the daily returns:\n",
        "\n",
        "$$\n",
        "\\text{ret}_{t_1:t_2} = \\sum_{t=t_1}^{t_2} \\text{ret}_t\n",
        "$$\n",
        "\n",
        "## Calculating Portfolio Risk (Standard Deviation)\n",
        "\n",
        "The standard deviation of portfolio returns, $\\text{sdp}_{t_1:t_2}$, is calculated using the same daily return values $\\text{ret}_t$ that were used to compute $\\text{ret}_{t_1:t_2}$. It is calculated as follows:\n",
        "\n",
        "$$\n",
        "\\text{varp}_{t_1:t_2} = \\frac{1}{T-1} \\sum_{t=t_1}^{t_2} \\left( \\text{ret}_t - \\frac{\\text{ret}_{t_1:t_2}}{T} \\right)^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{sdp}_{t_1:t_2} = \\sqrt{\\text{varp}_{t_1:t_2}}\n",
        "$$\n",
        "\n",
        "Here, $T$ is the length of the holding period and is defined as $T = t_2 - t_1 + 1$.\n",
        "\n",
        "## Interpretation of the Information Ratio (IR)\n",
        "\n",
        "A higher value of the Information Ratio ($\\text{IR}$)â€”which is the ratio of the portfolio return ($\\text{ret}$) to its standard deviation ($\\text{sdp}$)â€”indicates superior investment performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpFEOWF1_p52"
      },
      "source": [
        "Your example generally makes sense, but there are a couple of areas that could be clarified:\n",
        "\n",
        "1. You're annualizing both the return and the standard deviation, which is standard practice. However, the formulas could be more explicitly stated.\n",
        "  \n",
        "2. The expression \\(252/5 \\times 0.01\\) suggests that you are annualizing the summed daily returns (\\(ret_{1:5}=0.01\\)) by multiplying it by \\(252/5\\). This is a simplification, and a more accurate way to annualize would be to use compounding. Also, daily returns are usually averaged before annualization, unless you're summing them for a specific reason.\n",
        "\n",
        "3. Similarly, for standard deviation, it's more typical to multiply by \\(\\sqrt{252}\\) to annualize daily standard deviation.\n",
        "\n",
        "Here's your example revised for clarity:\n",
        "\n",
        "---\n",
        "\n",
        "**Example:**\n",
        "\n",
        "To calculate the Information Ratio (IR) for a one-week investment decision, we assume a 5-day assessment period. First, we determine the daily compounded returns, providing us with 5 $ret_t$ observations. Summing these observations gives $ret_{1:5} = 0.01$. Next, we find $sdp_{1:5} = 0.01$.\n",
        "\n",
        "Given that this is a 5-day period, the annualized return ($ret^a$) and the annualized standard deviation ($sdp^a$) can be calculated as:\n",
        "\n",
        "$$\n",
        "ret^a = (1 + ret_{1:5})^{252/5} - 1 \\approx 0.01 \\times \\frac{252}{5}\n",
        "$$\n",
        "\n",
        "$$\n",
        "sdp^a = sdp_{1:5} \\times \\sqrt{252}\n",
        "$$\n",
        "\n",
        "Thus, the Information Ratio for this period ($IR_{t_1:t_2}$) becomes:\n",
        "\n",
        "$$\n",
        "IR_{t_1:t_2} = \\frac{ret^a}{sdp^a} = \\frac{0.01 \\times \\frac{252}{5}}{\\sqrt{252} \\times 0.01} \\approx 0.79\n",
        "$$\n",
        "\n",
        "Note that, as with all our investment performance assessments, we utilize daily returns. This affords us more degrees of freedom when calculating the standard deviation, yielding a more accurate depiction of the investment's performance over the given period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTuJJNrTANLi"
      },
      "source": [
        "## A side note on annualization\n",
        "\n",
        "### Annualizing Returns\n",
        "\n",
        "For returns, we are interested in the total return over some period. In this example, we sum up the daily returns over a 5-day period, getting $ret_{1:5} = 0.01$. To annualize it, we multiply it by $\\frac{252}{5}$ since there are approximately 252 trading days in a year and we have 5 days of returns. This assumes simple returns and aims to scale the total 5-day return to what it would be over a whole year.\n",
        "\n",
        "However, the more accurate way to annualize compound returns is to use the formula:\n",
        "\n",
        "$$\n",
        "\\text{Annualized return} = \\left(1 + \\text{Average daily return} \\right)^{252} - 1\n",
        "$$\n",
        "\n",
        "Here we are taking the average of the 5 daily returns and then raise it to the 252nd power to annualize it, before subtracting 1 to get back to a return rate.\n",
        "\n",
        "### Annualizing Standard Deviation\n",
        "\n",
        "Standard deviation is a measure of risk or volatility, and it scales differently. For daily data, we can annualize the standard deviation by multiplying it by $\\sqrt{252}$ because standard deviation scales with the square root of time. Here, 252 comes from the approximate number of trading days in a year.\n",
        "\n",
        "Why don't we divide by 5 (or $\\sqrt{5}$)? Because we're not trying to reduce the annual standard deviation to a 5-day period; we're trying to take a 5-day standard deviation and scale it up to what it would be over a year. The $\\sqrt{252}$ helps project the standard deviation from the daily scale to an annual scale, given the square-root-of-time rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLRpj_yXMsvI",
        "outputId": "2bb1031c-9bfa-4000-dc1d-c8c4e8ea7681"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-4.3500470193669045"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Example\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define weights\n",
        "w = np.array([.2,.3,-.4])\n",
        "\n",
        "# Generate some synthetic stock prices, end of trading day, Fri -> Fri\n",
        "np.random.seed(10)\n",
        "S = np.random.normal(25, 6, size=(3, 6))\n",
        "\n",
        "def decision_performance(S, w):\n",
        "    eps = 1e-3\n",
        "    # Validate the sum of absolute weights\n",
        "    assert 1+eps > np.sum(np.abs(w)) and np.sum(np.abs(w)) >= 0.25, \"w is not conditioned well\"\n",
        "\n",
        "    # Handle cash\n",
        "    if np.sum(np.abs(w)) < 1:\n",
        "        w1 = 1 - np.sum(np.abs(w))\n",
        "    else:\n",
        "        w1 = 0\n",
        "    w = np.array(list(w) + [w1])\n",
        "\n",
        "    # Add cash to assets\n",
        "    cash = np.array([100,100,100,100,100,100])\n",
        "    S = np.vstack((S, cash))\n",
        "\n",
        "    # Calculate holding period return\n",
        "    RET = np.nansum(np.reshape(np.vstack(w),(-1,1)) * (S[:,1:] / S[:,:-1] - 1), axis=0)\n",
        "\n",
        "    # Calculate continuously compounded returns\n",
        "    ret = np.log(1 + RET)\n",
        "\n",
        "    # Calculate standard deviation and IR\n",
        "    std = np.nanstd(ret, ddof=1)\n",
        "    ret = np.nansum(ret)\n",
        "    ir = (252 / 5) * ret / (np.sqrt(252) * std)\n",
        "\n",
        "    return ir\n",
        "\n",
        "# Execute the function\n",
        "decision_performance(S, w)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jmN_9bQTEMU"
      },
      "source": [
        "# Measuring the Combined Performance of Forecasts and Investment Decisions\n",
        "\n",
        "The combined performance of forecasting and investment decisions is assessed using the arithmetic mean of the ranks for the Ranked Probability Score (RPS) and the Information Ratio (IR). Both forecasting and investment tasks are considered equally important. The Overall Rank (OR) for a particular submission at time $t$ is computed as follows:\n",
        "\n",
        "$$\n",
        "OR = \\frac{{\\text{rank}(RPS) + \\text{rank}(IR)}}{2}\n",
        "$$\n",
        "\n",
        "Here, $\\text{rank}(\\cdot)$ denotes the ranking of a participant's performance relative to all other participants for the given metric, either RPS or IR.\n",
        "\n",
        "For an aggregated view of forecasting performance across all 12 submission points, the arithmetic mean of the weekly RPS scores is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Up-NXDtZXw"
      },
      "source": [
        "# Submission example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrqMh0XgWyV_"
      },
      "source": [
        "# Submission Guidelines Summary\n",
        "\n",
        "* File Format: Submit your data in a CSV file. Google Sheets and XML formats are not accepted.\n",
        "* Filename: Name your file as `GROUPNAME__DATETIME.csv`, making sure to include double underscores.\n",
        "* Column Names: The CSV should have columns labeled \"id\", \"rank1\", \"rank2\", \"rank3\", \"rank4\", \"rank5\", and \"decision\". Do not include columns named \"symbol\" or \"name.\"\n",
        "* File Structure: Your file should comprise 7 columns and 110 rows, excluding the header row.\n",
        "* Unique IDs: Ensure that all \"id\" names are unique and correspond to the asset universe.\n",
        "* Rank Values: Entries in the \"rank\" columns should fall between 0 and 1.\n",
        "* Rank Sum: For each row, the sum of the values in the \"rank\" columns must be 1 or 0 if you are not investing in this name.\n",
        "* Decision Column: The sum of the absolute values in the \"decision\" column must be less than or equal to 1.\n",
        "* Notebook Usage: Use a copy of the provided notebooks for your work. Only edit the original notebooks if absolutely necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGz9YHgE5-vJ",
        "outputId": "38a3f6f9-760c-463e-b36c-097cf916ed79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.37)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.1)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2023.4)\n",
            "Mounted at /content/drive/\n",
            "fatal: destination path 'ddmif' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install pytz\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "import shutil\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "\n",
        "root_dir = '/content/drive/'\n",
        "drive.mount(root_dir)\n",
        "\n",
        "main_dir = root_dir+'MyDrive/ddmif_fall_2023/'\n",
        "data_dir = main_dir+'data/'\n",
        "ddmif_dir = root_dir+'MyDrive/ddmif'\n",
        "sys.path.append(main_dir)\n",
        "sys.path.append(data_dir)\n",
        "os.chdir(main_dir)\n",
        "\n",
        "ddmif_dir = root_dir+'MyDrive/ddmif_fall_2023/ddmif'\n",
        "try:\n",
        "  shutil.rmtree(ddmif_dir)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!git clone https://github.com/naftalic/ddmif.git\n",
        "import ddmif.ddmif_functions as ddmif\n",
        "#pip freeze > requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cntV0I1aq3n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "79fea576-6ad9-482f-8668-d05f069a3e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'append'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-212eac67479a>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#get price data from yahoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m assets_df  = ddmif.get_data(data_dir, universe_df, first_friday.strftime('%Y-%m-%d'), \\\n\u001b[0m\u001b[1;32m     14\u001b[0m              first_saturday.strftime('%Y-%m-%d'), first_sunday.strftime('%Y-%m-%d'), last_saturday.strftime('%Y-%m-%d'))\n\u001b[1;32m     15\u001b[0m \u001b[0massets_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/.shortcut-targets-by-id/12_JOCPOronN6NBZG1i8YkxXLE_hMLprI/ddmif_fall_2023/ddmif/ddmif_functions.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(data_dir, universe_df, first_friday, first_saturday, first_sunday, last_saturday)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0massets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0massets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
          ]
        }
      ],
      "source": [
        "first_friday = \"2023-10-06\"\n",
        "\n",
        "first_friday   = pd.to_datetime(first_friday, dayfirst=True)\n",
        "first_saturday = first_friday + pd.Timedelta(days=1)\n",
        "first_sunday   = first_friday + pd.Timedelta(days=2)\n",
        "last_saturday  = first_friday + pd.Timedelta(days=51)\n",
        "\n",
        "#get universe\n",
        "universe_file = 'universe.csv'\n",
        "universe_df   = ddmif.get_universe(data_dir, universe_file)\n",
        "\n",
        "#get price data from yahoo\n",
        "assets_df  = ddmif.get_data(data_dir, universe_df, first_friday.strftime('%Y-%m-%d'), \\\n",
        "             first_saturday.strftime('%Y-%m-%d'), first_sunday.strftime('%Y-%m-%d'), last_saturday.strftime('%Y-%m-%d'))\n",
        "assets_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPfet9ylBBya"
      },
      "source": [
        "1. asset_k_roc = (weighted_ma - last_day)/last_day\n",
        "2. map roc => rank ( if roc < -5% rank1 = 0.8 rank2 = 0.2 else = 0) (top 10 and last 10)\n",
        "3. rank => decision (roc => ranking  k 1st m 2nd )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmEv4ZXKNGsj"
      },
      "outputs": [],
      "source": [
        "def weighted_MA_roc(dataframe):\n",
        "    weighted_ma_roc = []\n",
        "    asset_symbols = dataframe.columns  # Capture the asset symbols (column names)  A list\n",
        "\n",
        "    weight = np.array([0.2 * i for i in range(dataframe.shape[0] -1)])  # Weight function is y = 0.2 x\n",
        "\n",
        "    for i in range(dataframe.shape[1]):\n",
        "        item = dataframe.iloc[:, i]  # Select the i-th column (asset)\n",
        "        #print(item)\n",
        "        roc = (item - item.shift(1) ) / item\n",
        "\n",
        "        roc.dropna(inplace=True)\n",
        "\n",
        "        roc = roc[roc != 0]\n",
        "\n",
        "\n",
        "\n",
        "        weighted_roc = weight[:len(roc)] * roc\n",
        "\n",
        "\n",
        "        # weighted_sum = item * weight  # Multiply the asset's prices by the weight\n",
        "        weighted_ma_i = np.sum(weighted_roc / np.sum(weight))  # Compute the weighted average\n",
        "\n",
        "        # last_day = item.iloc[-1]  # Get the last day's value\n",
        "        # roc = (weighted_ma_i - last_day) / last_day  # Calculate ROC\n",
        "        weighted_ma_roc.append(weighted_ma_i)\n",
        "\n",
        "    # Convert the list of ROC values to a Pandas Series with asset symbols as the index\n",
        "    roc_series = pd.Series(weighted_ma_roc, index=asset_symbols, name='ROC')\n",
        "\n",
        "    return roc_series\n",
        "\n",
        "# Calculate the ROC values\n",
        "roc_series = weighted_MA_roc(assets_df)\n",
        "\n",
        "# Print the ROC values\n",
        "print(roc_series[50:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGeQwBdA8XOB"
      },
      "outputs": [],
      "source": [
        "assets_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUQ7jCrJ_nw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame for illustration\n",
        "# Replace this with your actual dataframe of asset prices\n",
        "\n",
        "def bollinger_strategy(dataframe, window=20, k=2):\n",
        "    asset_returns = {}\n",
        "    for asset in dataframe.columns:\n",
        "        prices = dataframe[asset]\n",
        "\n",
        "        # Calculate moving average and standard deviation\n",
        "        sma = prices.rolling(window=window).mean()\n",
        "        rolling_std = prices.rolling(window=window).std()\n",
        "\n",
        "        # Calculate upper and lower Bollinger Bands\n",
        "        upper_band = sma + (rolling_std * k)\n",
        "        lower_band = sma - (rolling_std * k)\n",
        "\n",
        "        # Create signals: Buy (1), Hold (0), Sell (-1)\n",
        "        signals = pd.Series(index=prices.index)\n",
        "        signals[prices < lower_band] = 1\n",
        "        signals[prices > upper_band] = -1\n",
        "        signals = signals.ffill().fillna(0)\n",
        "\n",
        "        # Calculate returns\n",
        "        daily_returns = prices.pct_change()\n",
        "        strategy_returns = signals.shift() * daily_returns\n",
        "        total_return = (strategy_returns + 1).prod() - 1\n",
        "        asset_returns[asset] = total_return\n",
        "\n",
        "    # Rank assets based on returns\n",
        "    asset_ranking = pd.Series(asset_returns).sort_values(ascending=False)\n",
        "    return asset_ranking\n",
        "\n",
        "# Apply the Bollinger Band strategy and rank the assets\n",
        "ranking = bollinger_strategy(assets_df)\n",
        "print(\"Asset Ranking based on Bollinger Band Strategy:\")\n",
        "print(ranking)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxSsASdarNDq"
      },
      "source": [
        "## **MLP Strategy**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QIvoeDqreB5"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "67qd5LjkdNGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qUMC6hV55fl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "16d568b9-2fac-4785-db22-8adcd1e08fa1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'universe_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-467f3338c040>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mone_year_later\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_monday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_monday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_monday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m inputs_df  = ddmif.get_data(data_dir, universe_df, first_friday.strftime('%Y-%m-%d'), \\\n\u001b[0m\u001b[1;32m     15\u001b[0m              first_saturday.strftime('%Y-%m-%d'), first_sunday.strftime('%Y-%m-%d'), one_year_later.strftime('%Y-%m-%d'))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'universe_df' is not defined"
          ]
        }
      ],
      "source": [
        "# data cleaning\n",
        "#get price data from yahoo\n",
        "start_date = \"2022-11-03\"\n",
        "end_date = \"2023-11-05\"\n",
        "first_friday = \"2022-11-07\"\n",
        "\n",
        "first_friday   = pd.to_datetime(first_friday, dayfirst=True)\n",
        "first_saturday = first_friday + pd.Timedelta(days=6)\n",
        "first_sunday   = first_friday + pd.Timedelta(days=7)\n",
        "first_monday = first_friday + pd.Timedelta(days=1)\n",
        "\n",
        "one_year_later = pd.Timestamp(year=first_monday.year + 1, month=first_monday.month, day=first_monday.day  + 19)\n",
        "\n",
        "inputs_df  = ddmif.get_data(data_dir, universe_df, first_friday.strftime('%Y-%m-%d'), \\\n",
        "             first_saturday.strftime('%Y-%m-%d'), first_sunday.strftime('%Y-%m-%d'), one_year_later.strftime('%Y-%m-%d'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_df.head()"
      ],
      "metadata": {
        "id": "CPmHXzCGL5AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date = inputs_df.index[3]\n",
        "date2 = inputs_df.index[322]\n",
        "date3 = inputs_df.index[336]\n",
        "date4 = inputs_df.index[334]\n",
        "date5 = inputs_df.index[362]\n",
        "print(date, date2, date3, date4, date5)"
      ],
      "metadata": {
        "id": "bIWPgb9FQ1nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwJOnp4NjSY0"
      },
      "outputs": [],
      "source": [
        "print(inputs_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PKXmFfPWfKn"
      },
      "outputs": [],
      "source": [
        "inputs_df\n",
        "\n",
        "eq_col = []\n",
        "non_eq = []\n",
        "\n",
        "for col in inputs_df.columns:\n",
        "    if inputs_df[col].iloc[0] == inputs_df[col].iloc[1]:\n",
        "      eq_col.append(col)\n",
        "    else:\n",
        "      non_eq.append(col)\n",
        "\n",
        "print(eq_col,non_eq)\n",
        "\n",
        "eq_df = inputs_df #[eq_col]\n",
        "non_df = inputs_df[non_eq]\n",
        "\n",
        "eq_df1 = eq_df\n",
        "\n",
        "eq_df = ( eq_df - eq_df.shift(1)) / eq_df\n",
        "non_df = (non_df - non_df.shift(1)) / non_df\n",
        "\n",
        "# eq_df = eq_df.shift(1)\n",
        "# non_df = non_df.shift(-1)\n",
        "\n",
        "\n",
        "print(eq_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mghhXSt3DwS8"
      },
      "outputs": [],
      "source": [
        "print(eq_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlEfTSMu6kF1"
      },
      "outputs": [],
      "source": [
        "# df_rate_of_change = inputs_df.pct_change()\n",
        "# df_rate_of_change\n",
        "# df_rate_of_change = df_rate_of_change.iloc[1:-1]\n",
        "# cryptos = universe_df[universe_df['class'] == 'Crypto']\n",
        "# crypto_names = cryptos['symbol'].tolist()\n",
        "# for column in df_rate_of_change.columns:\n",
        "#     if column not in crypto_names:\n",
        "#         df_rate_of_change[column] = df_rate_of_change[column].interpolate(method='linear')\n",
        "\n",
        "# eq_df = eq_df.iloc[3:,:]\n",
        "print(eq_df.shape)\n",
        "\n",
        "xs = []  # List to store all x values\n",
        "ys = []  # List to store all y values\n",
        "\n",
        "xt = []  # List to store all x values\n",
        "yt = []  # List to store all y values\n",
        "\n",
        "for i in range(3, 370 - 48, 7):  # Sliding window logic\n",
        "    # For x values: Use the rate of change dataframe (roc_df)\n",
        "    for j in range(eq_df.shape[1]):\n",
        "      y_window = eq_df1.iloc[i:i+34,j]\n",
        "      if y_window.shape[0] > 32:\n",
        "        fourth_friday_price = y_window[25]\n",
        "\n",
        "        fifth_friday_price = y_window[32]\n",
        "        y = (fifth_friday_price - fourth_friday_price) / fourth_friday_price\n",
        "\n",
        "        ys.append(y)\n",
        "\n",
        "        x_window = eq_df.iloc[i:i+28,j]\n",
        "        x = x_window.values.flatten()\n",
        "        xs.append(x)\n",
        "\n",
        "\n",
        "for i in range(370 - 48, 370 - 34, 7):  # Sliding window logic\n",
        "    # For x values: Use the rate of change dataframe (roc_df)\n",
        "    for j in range(eq_df.shape[1]):\n",
        "      y_window = eq_df1.iloc[i:i+34,j]\n",
        "      if y_window.shape[0] > 32:\n",
        "        fourth_friday_price = y_window[25]\n",
        "\n",
        "        fifth_friday_price = y_window[32]\n",
        "        y = (fifth_friday_price - fourth_friday_price) / fourth_friday_price\n",
        "\n",
        "        yt.append(y)\n",
        "\n",
        "        x_window = eq_df.iloc[i:i+28,j]\n",
        "        x = x_window.values.flatten()\n",
        "        xt.append(x)\n",
        "\n",
        "      # # For y values: Use the original price dataframe (price_df)\n",
        "      # y_window = eq_df.iloc[j,i:i+34]\n",
        "      # fourth_friday_price = y_window[25]\n",
        "      # print(y_window.shape)\n",
        "      # fifth_friday_price = y_window[32]\n",
        "      # y = (fifth_friday_price - fourth_friday_price) / fourth_friday_price\n",
        "\n",
        "      # ys.append(y)\n",
        "\n",
        "\n",
        "xtest = []\n",
        "ytest = []\n",
        "\n",
        "for j in range(eq_df.shape[1]):\n",
        "\n",
        "  x_window = eq_df.iloc[362 - 28: 362 ,j]\n",
        "  x = x_window.values.flatten()\n",
        "  xtest.append(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert xs and ys to numpy arrays for further processing\n",
        "xs = np.array(xs)\n",
        "ys = np.array([ys]).T\n",
        "\n",
        "xt = np.array(xt)\n",
        "yt = np.array([yt]).T\n",
        "\n",
        "xtest = np.array(xtest)\n",
        "\n",
        "print(xs.shape)  # should be (48, 3080)\n",
        "print(ys.shape)  # should be (48, 110)\n",
        "\n",
        "print(xt.shape)  # should be (48, 3080)\n",
        "print(yt.shape)  # should be (48, 110)\n",
        "\n",
        "print(xtest.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zio6B6BrH_7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "# Your data (dummy example)\n",
        "# xs = np.random.rand(48, 3080)\n",
        "# ys = np.random.rand(48, 110)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.FloatTensor(xs)\n",
        "Y_tensor = torch.FloatTensor(ys)\n",
        "\n",
        "X_ = torch.FloatTensor(xt)\n",
        "Y_= torch.FloatTensor(yt)\n",
        "\n",
        "print(X_tensor.shape)\n",
        "\n",
        "# Create a DataLoader for your training and validation sets\n",
        "train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_, Y_)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCnlwlXSrndq"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28, 64)  # Corrected to 3080 input features\n",
        "        self.fc2 = nn.Linear(64, 16)\n",
        "        self.fc3 = nn.Linear(16, 1)  # 110 output features to match ys\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = MLP()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n09jtXYtrvxU"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ou_9h2rzMw"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()  # Mean Squared Error for regression tasks\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(150):  # Number of epochs\n",
        "    for batch_X, batch_Y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_X)\n",
        "        loss = criterion(output, batch_Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_Y in test_loader:\n",
        "\n",
        "            output = model(batch_X)\n",
        "\n",
        "\n",
        "            loss = criterion(output, batch_Y)\n",
        "            total_loss += loss.item() * batch_X.size(0)\n",
        "\n",
        "\n",
        "            total_samples += batch_X.size(0)\n",
        "\n",
        "\n",
        "    average_loss = total_loss / total_samples\n",
        "\n",
        "    # Validation logic\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}ï¼Œ Eval: {average_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5avg-puJ9w6U"
      },
      "outputs": [],
      "source": [
        "print(np.isnan(xs).any(), np.isnan(ys).any())\n",
        "print(np.isinf(xs).any(), np.isinf(ys).any())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAH0yRthqX2m"
      },
      "outputs": [],
      "source": [
        "mlpout = []\n",
        "X = torch.FloatTensor(xtest)\n",
        "for i in range(xtest.shape[0]):\n",
        "  pred = model(X[i].reshape(-1))\n",
        "  mlpout.append(pred.detach().cpu().numpy()[0])\n",
        "print(mlpout[2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddQBlUuEE-Jr"
      },
      "outputs": [],
      "source": [
        "mlpout = pd.Series(mlpout)\n",
        "\n",
        "from scipy.stats import zscore\n",
        "print(zscore(mlpout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnW3O9pUsBpm"
      },
      "source": [
        "## **Final Combination**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruPa8uHvAStm"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "def combined_ranking(dataframe,mlp):\n",
        "    # Calculate ROC ranking\n",
        "    roc_series = weighted_MA_roc(dataframe)\n",
        "\n",
        "    # Calculate Bollinger Band strategy ranking\n",
        "    bollinger_ranking = bollinger_strategy(dataframe)\n",
        "\n",
        "\n",
        "    # Normalize using Z-score\n",
        "\n",
        "    zscore_roc = zscore(roc_series)\n",
        "    zscore_bollinger = zscore(bollinger_ranking)\n",
        "    mlp = zscore(mlp)\n",
        "\n",
        "    # Assign weights\n",
        "    w1, w2, w3 = 0.3, 0.01, 0.2\n",
        "    mlp.index = roc_series.index\n",
        "    # Combine the Z-scores\n",
        "    combined_zscore = w1*zscore_roc + w2*zscore_bollinger + w3 *mlp\n",
        "\n",
        "    # Create final ranking\n",
        "    combined_ranking_series = pd.Series(combined_zscore, index=roc_series.index)#.sort_values(ascending=False)\n",
        "\n",
        "    return combined_ranking_series\n",
        "\n",
        "# Apply the combined ranking\n",
        "final_ranking = combined_ranking(assets_df, mlpout)\n",
        "\n",
        "print(\"Final Combined Asset Ranking:\")\n",
        "print(final_ranking[50:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3IcqJVql7Bk"
      },
      "outputs": [],
      "source": [
        "rank = final_ranking.sort_values(ascending=False)\n",
        "print(rank[:20],rank[100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBB5JWr6LB-b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ªpd.Serieså¯¹è±¡\n",
        "\n",
        "\n",
        "# ä½¿ç”¨Matplotlibç»˜åˆ¶ç›´æ–¹å›¾\n",
        "plt.hist(final_ranking, bins=50, edgecolor='black')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Series')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4LW0LQKQG6o"
      },
      "outputs": [],
      "source": [
        "print(final_ranking[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNqL7_N8FTrM"
      },
      "source": [
        "\n",
        "\n",
        "CZR score 0.795 => score_classification [0.01,0.09,0.1,0.2,0.6]   [r1,r2,r3,r4,r5] = [-2 , -1.2 , -0.4, 0.4, 1.2]  N(0.795 , sigma) pdf(r1,r2,r3,r4,r5) = [0.01, 0.015 0.02, 0.04 , 0.99] softmax => normalized score [r1.r2,r5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVEXqXpGcdr1"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "def get_cdf(x):\n",
        "  std = 1\n",
        "  seg = np.array([-1000, -1.0 , -0.3 , 0.3, 1.0, 1000] )#segment\n",
        "  cdf = stats.norm.cdf(seg, loc=x, scale=std)\n",
        "  cdf = np.diff(cdf)\n",
        "  return cdf # normalized ranking score\n",
        "\n",
        "asset_names = assets_df.columns.tolist()  # Extract column names from assets_df\n",
        "df = pd.DataFrame(0, index=asset_names, columns=[f'rank{i+1}' for i in range(5)])\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "for i in range(df.shape[0]):\n",
        "  prob = get_cdf(final_ranking[i])\n",
        "  for j in range(5):\n",
        "    df.loc[asset_names[i], 'rank'+str(j+1)] = prob[j] = prob[j]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Map to brackets based on probabilities\n",
        "# # We use digitize to get bin numbers, starting from 0, so we add 1 to start from 1.\n",
        "# brackets = np.digitize(probabilities, [0.2, 0.4, 0.6, 0.8]) + 1\n",
        "# print(brackets)\n",
        "\n",
        "# # Create DataFrame\n",
        "# asset_names = assets_df.columns.tolist()  # Extract column names from assets_df\n",
        "# df = pd.DataFrame(0, index=asset_names, columns=[f'rank{i+1}' for i in range(5)])\n",
        "\n",
        "# # Populate DataFrame based on brackets\n",
        "# for asset, rank in zip(asset_names, brackets):\n",
        "#     df.loc[asset, f'rank{rank}'] = 1.0\n",
        "\n",
        "print(\"Do all rows sum to 1?:\", df.sum(axis=1).eq(1.0).all())\n",
        "print(df.iloc[:40])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scj5YlQ6mBx-"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame containing the names and final_ranking values\n",
        "ranking_df = pd.DataFrame({'Stock Name': final_ranking.index, 'Final Ranking': final_ranking.values})\n",
        "\n",
        "# Sort the DataFrame by 'Final Ranking' in descending order to get the top 20 stocks\n",
        "top_20_stocks = ranking_df.sort_values(by='Final Ranking', ascending=False).head(30)\n",
        "top_20_stocks = top_20_stocks[top_20_stocks['Final Ranking'] > 0.25]\n",
        "\n",
        "# Sort the DataFrame by 'Final Ranking' in ascending order to get the worst 20 stocks\n",
        "worst_20_stocks = ranking_df.sort_values(by='Final Ranking', ascending=True).head(30)\n",
        "worst_20_stocks = worst_20_stocks[worst_20_stocks['Final Ranking'] < -0.3]\n",
        "\n",
        "# Concatenate the filtered top and worst 20 stocks\n",
        "selected_stocks_df = pd.concat([top_20_stocks, worst_20_stocks])\n",
        "\n",
        "# Reset the index of the selected_stocks_df\n",
        "selected_stocks_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Create a new DataFrame with absolute values of 'Final Ranking'\n",
        "selected_stocks_abs_df = selected_stocks_df.copy()\n",
        "selected_stocks_abs_df['Final Ranking'] = selected_stocks_df['Final Ranking'].abs()\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "# print(selected_stocks_df, selected_stocks_abs_df)\n",
        "\n",
        "# Extract the absolute values of 'Final Ranking' column\n",
        "abs_rankings = selected_stocks_abs_df['Final Ranking'].values\n",
        "\n",
        "# Apply softmax to the absolute values\n",
        "softmax_values = softmax(abs_rankings)\n",
        "\n",
        "\n",
        "\n",
        "# Create a new DataFrame with softmax values and stock names\n",
        "softmax_df = pd.DataFrame({'Stock Name': selected_stocks_abs_df['Stock Name'], 'Softmax Value': softmax_values})\n",
        "\n",
        "merged_df = selected_stocks_df.merge(softmax_df, on='Stock Name', how='inner')\n",
        "\n",
        "\n",
        "# Filter stocks with positive and negative 'Final Ranking' values\n",
        "long_stocks = merged_df[merged_df['Final Ranking'] > 0]\n",
        "short_stocks = merged_df[merged_df['Final Ranking'] < 0]\n",
        "\n",
        "# Calculate the weights for long and short positions based on softmax values\n",
        "long_weights = long_stocks['Softmax Value']\n",
        "short_weights = -short_stocks['Softmax Value']\n",
        "\n",
        "# Create portfolios for long and short positions\n",
        "long_portfolio = pd.DataFrame({'Stock Name': long_stocks['Stock Name'], 'Weight': long_weights})\n",
        "short_portfolio = pd.DataFrame({'Stock Name': short_stocks['Stock Name'], 'Weight': short_weights})\n",
        "\n",
        "# Combine the long and short portfolios to create the final portfolio\n",
        "portfolio = pd.concat([long_portfolio, short_portfolio])\n",
        "\n",
        "# Print the final portfolio\n",
        "print(\"Final Portfolio:\")\n",
        "print(portfolio)\n",
        "\n",
        "sum_absolute_weights = abs(portfolio['Weight']).sum()\n",
        "\n",
        "\n",
        "print(\"Sum of Absolute Weights in Portfolio:\", sum_absolute_weights)\n",
        "\n",
        "portfolio.set_index('Stock Name', inplace=True)\n",
        "\n",
        "df_final = df.join(portfolio)\n",
        "\n",
        "df_final['Weight'].fillna(0, inplace=True)\n",
        "\n",
        "df_final.rename(columns={'Weight': 'decision'}, inplace=True)\n",
        "\n",
        "print(df_final)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFztZI06-ZAc"
      },
      "outputs": [],
      "source": [
        "print(df_final)\n",
        "\n",
        "df_final['i'] = df_final.index\n",
        "\n",
        "\n",
        "df_final.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "df_final.index = [f'{i}' for i in range(len(df_final))]\n",
        "\n",
        "print(df_final)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQLLvio3BRCF"
      },
      "outputs": [],
      "source": [
        "last_column = df_final.iloc[:, -1]\n",
        "\n",
        "df_final.insert(0, 'id', last_column)\n",
        "\n",
        "df_final.drop(df_final.columns[-1], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRGYiKCkpjZq"
      },
      "outputs": [],
      "source": [
        "print(df_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5cqGd8h5G0f"
      },
      "outputs": [],
      "source": [
        "# # Assuming you have 'roc_series', 'portfolio', and 'merged_df' DataFrames already defined\n",
        "\n",
        "# # Convert 'roc_series' to a DataFrame and reset its index\n",
        "# roc_df = roc_series.reset_index()\n",
        "\n",
        "# # Rename the columns to match your requirements\n",
        "# roc_df.columns = ['id', 'rank1']\n",
        "\n",
        "# # Merge 'roc_df' with 'portfolio' on 'Stock Name' to get ranks\n",
        "# merged_ranks_df = roc_df.merge(portfolio, left_on='id', right_on='Stock Name', how='left')\n",
        "\n",
        "# # Create the new DataFrame with the specified columns\n",
        "# new_df = merged_ranks_df[['id', 'rank1', 'rank2', 'rank3', 'rank4', 'rank5', 'decision']].copy()\n",
        "\n",
        "# # Fill NaN values in 'decision' column with 0\n",
        "# new_df['decision'].fillna(0, inplace=True)\n",
        "\n",
        "# # Print the new DataFrame\n",
        "# print(new_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTwF34F5K2XB"
      },
      "source": [
        "top20 [x1,...,x20]  last[y1,...,y20] (make sure top 20 are positive and last 20 are negative)=> [s1,...,s40] => softmax => normalized score (40 assets) * (0.9) 0.95 1 => decisions [] (top 20 are positive and last 20 are negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAgz7cnZlodD"
      },
      "outputs": [],
      "source": [
        "# def filter_non_zero_decisions_and_check_sum(ranks_df):\n",
        "#     # Filter out rows where 'decision' is not 0\n",
        "#     non_zero_decisions = ranks_df[ranks_df['decision'] != 0]['decision']\n",
        "\n",
        "#     # Calculate the sum of the absolute values\n",
        "#     abs_sum = non_zero_decisions.abs().sum()\n",
        "\n",
        "#     print(\"Sum of absolute values of non-zero decisions:\", abs_sum)\n",
        "\n",
        "#     # Check the sum against your criteria\n",
        "#     if abs_sum <= 1 and abs_sum > 0.25:\n",
        "#         print(\"The sum of absolute values is within the specified criteria.\")\n",
        "#     else:\n",
        "#         print(\"The sum of absolute values is NOT within the specified criteria.\")\n",
        "\n",
        "#     return non_zero_decisions\n",
        "\n",
        "# # Assuming 'ranks' DataFrame has a 'decision' column\n",
        "# # Run this function to get the non-zero decisions and check their absolute sum\n",
        "# non_zero_decisions = filter_non_zero_decisions_and_check_sum(ranks)\n",
        "\n",
        "# print(\"Non-zero decisions:\")\n",
        "# print(non_zero_decisions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkbofwy9qRDY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Rename the sorted DataFrame to submission_file\n",
        "submission_file = df_final\n",
        "\n",
        "print(\"submission_file DataFrame:\")\n",
        "print(submission_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pajYRvVvqQNH"
      },
      "outputs": [],
      "source": [
        "# Reset the index and create a new column 'id' which will hold the index (asset symbols)\n",
        "submission_file = df_final\n",
        "\n",
        "# submission_file['id'] = submission_file.index\n",
        "\n",
        "# submission_file.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Rename the columns to match the desired format\n",
        "# submission_file.columns = ['id', 'rank1', 'rank2', 'rank3', 'rank4', 'rank5', 'decision']\n",
        "\n",
        "# Display the modified DataFrame\n",
        "print(\"Modified submission_file DataFrame:\")\n",
        "print(df_final)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnzjROCqrx2G"
      },
      "outputs": [],
      "source": [
        "#submission file example:\n",
        "\n",
        "N = 110\n",
        "# num_groups = 5\n",
        "\n",
        "# for i in range(num_groups):\n",
        "\n",
        "est = pytz.timezone('US/Eastern')  # Get the US Eastern Time Zone\n",
        "current_time = datetime.now(est)  # Get the current time in EST\n",
        "submission_time = current_time.strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "\n",
        "submission_dir = main_dir+'submissions/dueNov26/'\n",
        "filename = 'DYF_'+'__'+submission_time+ '.csv'\n",
        "df_final.to_csv(submission_dir+filename)\n",
        "print(submission_dir+filename)\n",
        "print(submission_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVn2zWHRsCR9"
      },
      "outputs": [],
      "source": [
        "# #submission file example:\n",
        "\n",
        "# N = 110\n",
        "# # num_groups = 5\n",
        "\n",
        "# # for i in range(num_groups):\n",
        "\n",
        "# est = pytz.timezone('US/Eastern')  # Get the US Eastern Time Zone\n",
        "# current_time = datetime.now(est)  # Get the current time in EST\n",
        "# submission_time = current_time.strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "# feature_list          = ['id', 'rank1', 'rank2', 'rank3', 'rank4','rank5', 'decision']\n",
        "# submission_file       = pd.DataFrame(0, index=np.arange(N), columns = feature_list)\n",
        "# submission_file['id'] = universe_df['symbol'].copy()\n",
        "\n",
        "# x = np.random.uniform(0, 1, size=(N, 5))\n",
        "# submission_file[['rank1', 'rank2', 'rank3', 'rank4','rank5']] = x / np.reshape(np.sum(x,axis=1),(-1,1))\n",
        "\n",
        "# x = np.reshape(np.random.normal(0, .05, size=N), (-1,1))\n",
        "# submission_file[['decision']] = x/np.sum(np.abs(x))\n",
        "\n",
        "# submission_dir = main_dir+'submissions/dueSep17/'\n",
        "# filename = 'XYZ_'+'__'+submission_time\n",
        "# submission_file.to_csv(submission_dir+filename)\n",
        "# print(submission_dir+filename)\n",
        "# print(submission_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I33RNZi42eRV"
      },
      "outputs": [],
      "source": [
        "# # 'fake' real data\n",
        "# mean_price = 100\n",
        "# std_price  = 20\n",
        "# np.random.seed(10)\n",
        "# S = np.random.normal(mean_price, std_price, size=(110, 6))\n",
        "\n",
        "# vector = S[:,-1]/S[:,0]\n",
        "\n",
        "# def quintile_rank_with_average_tie(vector):\n",
        "#   data = pd.DataFrame({'value':vector, 'dense_rank':np.argsort(np.argsort(vector))})\n",
        "#   data['quintile'] = pd.qcut(data['dense_rank'], q=5, labels=range(1, 6)).astype('float32')\n",
        "#   data['quintile_rank'] = data.groupby('value')['quintile'].transform(lambda x: x.mean())\n",
        "#   return data['quintile_rank'].values\n",
        "\n",
        "# def map_to_vector(vector):\n",
        "#     quintile_vector = np.zeros((len(vector), 5))\n",
        "#     for i in range(len(vector)):\n",
        "#         quintile_vector[i, int(vector[i])-1] = 1\n",
        "#         if np.abs(int(vector[i])-vector[i])>0:\n",
        "#           quintile_vector[i, int(np.ceil(vector[i]))-1]  = vector[i]-np.floor(vector[i])\n",
        "#           quintile_vector[i, int(np.floor(vector[i]))-1] = np.ceil(vector[i])-vector[i]\n",
        "#     return quintile_vector\n",
        "\n",
        "# vector = S[:,-1]/S[:,0]\n",
        "# quintile_rank = quintile_rank_with_average_tie(vector)\n",
        "# q = map_to_vector(quintile_rank)\n",
        "\n",
        "# print(np.sum(q,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKY13TdQsPPC"
      },
      "outputs": [],
      "source": [
        "# submission_dir = main_dir+'submissions/dueOct1/'\n",
        "# symbols = universe_df.sort_values(by=['symbol'])['symbol']\n",
        "# eps = 1e-3\n",
        "# from glob import glob\n",
        "# lst = glob(submission_dir+'/*')\n",
        "\n",
        "# stats = pd.DataFrame(columns=['group_name','forecast_performance','decision_performance'])\n",
        "# group_name = []\n",
        "\n",
        "# for i in range(len(lst)):\n",
        "\n",
        "#   try:\n",
        "#     ddmif.eval_submission_file(lst[i], universe_df)\n",
        "\n",
        "#     df = pd.read_csv(lst[i],sep=\",\", header=0,index_col=0).sort_values(by=['id'])\n",
        "#     f = df[['rank1', 'rank2', 'rank3', 'rank4','rank5']].to_numpy()\n",
        "#     w = np.reshape(df['decision'].to_numpy(),(-1,1))\n",
        "#     stats.loc[i,:] = lst[i].split('/')[-1].split('__')[0], forecast_performance(f, q), decision_performance(S, w)\n",
        "#   except:\n",
        "#     print('******************')\n",
        "#     print(\"**Problem** with file:\", i, lst[i].split('/')[-1])\n",
        "#     stats.loc[i,:] = lst[i].split('/')[-1].split('__')[0], 1e6, 1e6\n",
        "\n",
        "# stats['overall_rank'] = (pd.Series(stats['forecast_performance']).rank(method='dense') +\\\n",
        "#                                      pd.Series(stats['decision_performance']).rank(method='dense'))/2\n",
        "\n",
        "# scoring_dir = main_dir+'scoring/'\n",
        "# stats.to_csv(scoring_dir+'dueOct1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGjhRREpFpsH"
      },
      "outputs": [],
      "source": [
        "# lst2 = glob(scoring_dir+'/*')\n",
        "\n",
        "# for i in range(len(lst2)):\n",
        "#   df = pd.read_csv(lst2[i],sep=\",\", header=0,index_col=0)\n",
        "#   if i==0:\n",
        "#     final_stats = pd.DataFrame()\n",
        "#     final_stats['group_name'] = df['group_name']\n",
        "#   final_stats['OR_'+str(i)] = df['overall_rank']\n",
        "\n",
        "# cols = [i for i in final_stats.columns if 'OR' in i]\n",
        "# final_stats['mean_OR'] = final_stats[cols].mean(axis=1)\n",
        "\n",
        "# final_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJAff6LkK5mh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO2RDVeZ5u2J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dj8_CF14rNj"
      },
      "source": [
        "Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubhkLViy4sc4"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Assuming universe_df is your DataFrame containing asset symbols\n",
        "tickers = universe_df['symbol']\n",
        "\n",
        "# Define the start and end dates for backtesting\n",
        "end_date = datetime.today().strftime('%Y-%m-%d')\n",
        "start_date = '2017-01-01'  # Adjust as per your backtesting period\n",
        "\n",
        "print(f\"Start Date: {start_date}, End Date: {end_date}\")\n",
        "print('*' * 80)\n",
        "\n",
        "# Function to check if the stock has sufficient historical data\n",
        "def validate_stock_history(stock):\n",
        "    listing_date = stock.history(period=\"max\").index[0].to_pydatetime().date()\n",
        "    required_history_date = (datetime.today() - timedelta(days=2*365)).date()\n",
        "    return listing_date <= required_history_date\n",
        "\n",
        "# DataFrame to hold all historical data\n",
        "all_data = pd.DataFrame()\n",
        "\n",
        "# Download historical data for each ticker\n",
        "for ticker in tickers:\n",
        "    stock = yf.Ticker(ticker)\n",
        "\n",
        "    # Validate stock history\n",
        "    if validate_stock_history(stock):\n",
        "        df = stock.history(start=start_date, end=end_date, auto_adjust=True)\n",
        "        df['ticker'] = ticker\n",
        "        df['name'] = stock.info['longName']\n",
        "        df = df.rename(columns={\"Close\": \"close\"})\n",
        "        df = df[['name', 'ticker', 'close']]\n",
        "        all_data = pd.concat([all_data, df], axis=0)\n",
        "    else:\n",
        "        print(f\"Skipping {ticker} as it does not have sufficient history\")\n",
        "\n",
        "# Reset index and rename 'Date' column\n",
        "all_data.reset_index(inplace=True)\n",
        "all_data = all_data.rename(columns={\"Date\": \"date\"})\n",
        "\n",
        "# Optionally, save the data to a CSV file\n",
        "# all_data.to_csv('historical_stock_data.csv', index=False)\n",
        "\n",
        "all_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTNPjsOWqXOY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load your prepared data\n",
        "# Assuming all_data is already loaded from your previous steps\n",
        "# all_data = pd.read_csv('path_to_your_prepared_data.csv')  # Uncomment and set the path if needed\n",
        "\n",
        "# Function to calculate WMA and future weekly returns\n",
        "def calculate_wma_and_weekly_return(df, window=20):\n",
        "    # Calculate the weights for WMA\n",
        "    weights = np.arange(1, window + 1)\n",
        "\n",
        "    # Function to calculate WMA for a given series\n",
        "    def wma(series):\n",
        "        return np.sum(weights * series) / np.sum(weights)\n",
        "\n",
        "    # Apply WMA calculation to each stock's data\n",
        "    df['WMA'] = df.groupby('ticker')['close'].transform(lambda x: x.rolling(window=window).apply(wma, raw=True))\n",
        "\n",
        "    # Calculate future weekly return\n",
        "    df['Future_Weekly_Return'] = df.groupby('ticker')['close'].shift(-5) / df['close'] - 1\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the function to the all_data DataFrame\n",
        "enhanced_data = calculate_wma_and_weekly_return(all_data)\n",
        "\n",
        "# Displaying the first few rows of the enhanced data\n",
        "print(enhanced_data.head())\n",
        "\n",
        "# Optionally, you can save this data to a CSV file\n",
        "# enhanced_data.to_csv('enhanced_stock_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_MA_roc(df, window=20):\n",
        "    weighted_ma_roc = pd.DataFrame()\n",
        "\n",
        "    # Weight function: y = 0.2 * x\n",
        "    weights = np.array([0.2 * i for i in range(window)])\n",
        "\n",
        "    for ticker in df['ticker'].unique():\n",
        "        single_stock_data = df[df['ticker'] == ticker].copy()\n",
        "        single_stock_data.sort_values(by='date', inplace=True)\n",
        "\n",
        "        # Calculate Rate of Change (ROC)\n",
        "        roc = (single_stock_data['close'] - single_stock_data['close'].shift(1)) / single_stock_data['close']\n",
        "\n",
        "        # Ensure the lengths match by trimming the dataframe\n",
        "        single_stock_data = single_stock_data.iloc[window-1:]\n",
        "\n",
        "        # Check if there are enough data points\n",
        "        if len(roc) >= window:\n",
        "            roc.dropna(inplace=True)\n",
        "\n",
        "            # Apply weights to ROC\n",
        "            weighted_roc = np.convolve(roc, weights, mode='valid') / np.sum(weights)\n",
        "\n",
        "            # Add results to DataFrame\n",
        "            single_stock_data = single_stock_data.iloc[:len(weighted_roc)]\n",
        "            single_stock_data['Weighted_MA_ROC'] = weighted_roc\n",
        "            weighted_ma_roc = pd.concat([weighted_ma_roc, single_stock_data])\n",
        "\n",
        "    return weighted_ma_roc\n"
      ],
      "metadata": {
        "id": "gPCunK6HQnRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weighted moving average ROC\n",
        "roc_data = weighted_MA_roc(all_data)\n",
        "\n",
        "# Merge the ROC data with enhanced_data\n",
        "enhanced_data_with_roc = enhanced_data.merge(roc_data, on=['date', 'ticker'])\n",
        "\n",
        "# Proceed with your existing backtesting code, replacing WMA with Weighted_MA_ROC\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "Lpi2nSc-QrMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(enhanced_data.tail())"
      ],
      "metadata": {
        "id": "YmHBOSaD1M8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy statsmodels plotly\n"
      ],
      "metadata": {
        "id": "NmyoGDjf11fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enhanced_data_cleaned = enhanced_data.dropna(subset=['WMA', 'Future_Weekly_Return'])"
      ],
      "metadata": {
        "id": "T-uvogDt5ubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming enhanced_data is already loaded\n",
        "\n",
        "# Convert 'date' column to datetime format\n",
        "enhanced_data['date'] = pd.to_datetime(enhanced_data['date'], errors='coerce', utc=True)\n",
        "\n",
        "# Remove timezone information\n",
        "enhanced_data['date'] = enhanced_data['date'].dt.tz_localize(None)\n",
        "\n"
      ],
      "metadata": {
        "id": "JUSTLqD2S38-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import plotly.express as px\n",
        "\n",
        "# Assuming enhanced_data is already loaded with WMA and Future_Weekly_Return\n",
        "# ... other parts of the code ...\n",
        "\n",
        "# Ensure the 'date' column is in datetime format\n",
        "enhanced_data['date'] = pd.to_datetime(enhanced_data['date'])\n",
        "\n",
        "# Perform the regression and subsequent analysis\n",
        "results = []\n",
        "\n",
        "train_end = pd.to_datetime('2020-12-31')\n",
        "val_end = pd.to_datetime('2022-12-31')\n",
        "train_window_size = 52\n",
        "val_window_size = 1\n",
        "\n",
        "dates = sorted(enhanced_data['date'].unique())\n",
        "\n",
        "for start in range(0, len(dates) - train_window_size - val_window_size, val_window_size):\n",
        "    end = start + train_window_size\n",
        "    window_data = enhanced_data[(enhanced_data['date'] >= dates[start]) & (enhanced_data['date'] <= dates[end])]\n",
        "\n",
        "    t0 = window_data['date'].iloc[-1]\n",
        "    segment = 'oos' if t0 > val_end else 'val' if t0 > train_end else 'train'\n",
        "\n",
        "    next_window_data = enhanced_data[(enhanced_data['date'] > dates[end]) & (enhanced_data['date'] <= dates[end + val_window_size])]\n",
        "\n",
        "    regression_result = perform_regression(window_data, next_window_data, segment)\n",
        "    if regression_result:\n",
        "        end_date = window_data['date'].iloc[-1]\n",
        "        full_result = regression_result + (end_date,)\n",
        "        results.append(full_result)\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['intercept', 'slope', 'segment', 'x_train', 'y_train', 'x_test', 'y_test', 'y_pred', 'end_date'])\n",
        "\n",
        "# Plotting\n",
        "# Scatter plot for the last training segment\n",
        "last_train_segment = results_df[results_df['segment'] == 'train'].iloc[-1]\n",
        "fig = px.scatter(x=last_train_segment['x_train'], y=last_train_segment['y_train'], labels={'x':'WMA', 'y':'Future Weekly Return'}, title='WMA vs Future Weekly Return')\n",
        "fig.show()\n",
        "\n",
        "# Plot for slope over time\n",
        "fig = px.scatter(results_df, x='end_date', y='slope', color='segment', title='Slope of Regression Over Time')\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Slope')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "qM455wyNSHjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}